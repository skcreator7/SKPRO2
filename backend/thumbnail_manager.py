# ============================================================================
# thumbnail_manager.py - OPTIMIZED VERSION WITH MULTI-LAYER FALLBACKS
# ============================================================================

import asyncio
import base64
import logging
import time
import re
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Tuple, Callable
import hashlib
import aiohttp
import io

logger = logging.getLogger(__name__)

class ThumbnailManager:
    """OPTIMIZED Thumbnail management with multi-layer fallbacks"""
    
    def __init__(self, mongo_client, config, bot_handler=None):
        self.mongo_client = mongo_client
        self.db_name = "sk4film"
        self.db = mongo_client[self.db_name]
        self.thumbnails_col = self.db.thumbnails
        self.files_col = self.db.files
        self.config = config
        self.bot_handler = bot_handler
        
        # Enhanced Thumbnail cache
        self.thumbnail_cache = {}
        self.cache_ttl = 3600  # 1 hour
        
        # Telegram extraction methods with priorities
        self.telegram_extraction_methods = [
            self._extract_from_video_thumbnail,
            self._extract_from_document_thumbnail,
            self._extract_from_preview,
            self._extract_from_message_media
        ]
        
        # API Services - Expanded for 99.5% success rate
        self.api_services = [
            self._fetch_from_tmdb,
            self._fetch_from_omdb,
            self._fetch_from_imdb,
            self._fetch_from_letterboxd,
            self._fetch_from_wikipedia,
            self._fetch_from_trakt,
            self._fetch_from_youtube,
            self._fetch_from_google_images,
            self._fetch_from_rottentomatoes,
            self._fetch_from_metacritic,
            self._fetch_from_rapidapi,
            self._fetch_from_open_movie_database
        ]
        
        # Statistics
        self.stats = {
            'total_requests': 0,
            'successful': 0,
            'failed': 0,
            'from_cache': 0,
            'from_telegram': 0,
            'from_api': 0,
            'no_thumbnail': 0,
            'api_success_rate': {},
            'telegram_extraction_stats': {},
            'response_times': []
        }
        
        # API Keys
        self.tmdb_api_key = getattr(config, 'TMDB_API_KEY', '')
        self.omdb_api_key = getattr(config, 'OMDB_API_KEY', '')
        self.youtube_api_key = getattr(config, 'YOUTUBE_API_KEY', '')
        self.trakt_api_key = getattr(config, 'TRAKT_API_KEY', '')
        self.rapidapi_key = getattr(config, 'RAPIDAPI_KEY', '')
    
    async def initialize(self):
        """Initialize thumbnail manager"""
        logger.info("üñºÔ∏è Initializing OPTIMIZED Thumbnail Manager...")
        
        try:
            await self.db.command('ping')
            logger.info(f"‚úÖ Database connection verified: {self.db_name}")
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            return False
        
        # Clean up existing duplicates first
        await self._cleanup_existing_issues()
        
        # Create indexes
        await self.create_indexes()
        
        logger.info("‚úÖ OPTIMIZED Thumbnail Manager initialized")
        logger.info("üéØ FEATURES:")
        logger.info("   ‚Ä¢ One Movie ‚Üí One Thumbnail")
        logger.info("   ‚Ä¢ Multi-layer Telegram extraction")
        logger.info("   ‚Ä¢ 12+ API fallback services")
        logger.info("   ‚Ä¢ 99.5% success rate target")
        logger.info("   ‚Ä¢ Smart title normalization")
        
        return True
    
    async def _cleanup_existing_issues(self):
        """Clean up existing database issues"""
        try:
            # Remove problematic documents with null values
            result = await self.thumbnails_col.delete_many({
                "$or": [
                    {"channel_id": None},
                    {"message_id": None},
                    {"channel_id": {"$exists": False}},
                    {"message_id": {"$exists": False}}
                ]
            })
            
            if result.deleted_count > 0:
                logger.info(f"üßπ Cleaned {result.deleted_count} problematic documents")
            
            # Drop problematic index if exists
            try:
                await self.thumbnails_col.drop_index("thumbnails_message_unique")
                logger.info("‚úÖ Dropped problematic index")
            except Exception:
                pass
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Cleanup error: {e}")
    
    async def create_indexes(self):
        """Create optimized MongoDB indexes"""
        try:
            # TTL index for automatic cleanup (30 days)
            ttl_days = getattr(self.config, 'THUMBNAIL_TTL_DAYS', 30)
            if ttl_days > 0:
                await self.thumbnails_col.create_index(
                    [("last_accessed", 1)],
                    expireAfterSeconds=ttl_days * 24 * 60 * 60,
                    name="thumbnails_ttl_index",
                    background=True
                )
                logger.info(f"‚úÖ TTL index created ({ttl_days} days)")
            
            # Normalized title unique index (Most Important)
            try:
                await self.thumbnails_col.create_index(
                    [("normalized_title", 1)],
                    unique=True,
                    name="thumbnails_title_unique",
                    background=True
                )
                logger.info("‚úÖ Normalized title unique index created")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Unique index error: {e}")
            
            # Channel + Message ID index (sparse for non-null values)
            try:
                await self.thumbnails_col.create_index(
                    [("channel_id", 1), ("message_id", 1)],
                    sparse=True,
                    name="thumbnails_message_index",
                    background=True
                )
                logger.info("‚úÖ Sparse message index created")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Message index error: {e}")
            
            # Source index for analytics
            await self.thumbnails_col.create_index(
                [("source", 1)],
                name="thumbnails_source_index",
                background=True
            )
            
            logger.info("‚úÖ All indexes created/verified")
            
        except Exception as e:
            logger.error(f"‚ùå Error creating indexes: {e}")
    
    async def extract_thumbnail_with_fallbacks(self, channel_id: int, message_id: int) -> Optional[str]:
        """
        Extract thumbnail using multiple Telegram methods
        Returns base64 data URL or None
        """
        if not channel_id or not message_id:
            logger.debug("Invalid channel_id or message_id")
            return None
        
        # Initialize stats for this method if not exists
        method_name = "telegram_fallbacks"
        if method_name not in self.stats['telegram_extraction_stats']:
            self.stats['telegram_extraction_stats'][method_name] = {
                'attempts': 0,
                'success': 0,
                'failures': 0
            }
        
        self.stats['telegram_extraction_stats'][method_name]['attempts'] += 1
        
        for method in self.telegram_extraction_methods:
            method_func = method
            method_name = method.__name__
            
            # Initialize stats for this specific method
            if method_name not in self.stats['telegram_extraction_stats']:
                self.stats['telegram_extraction_stats'][method_name] = {
                    'attempts': 0,
                    'success': 0,
                    'failures': 0
                }
            
            self.stats['telegram_extraction_stats'][method_name]['attempts'] += 1
            
            try:
                thumbnail = await method_func(channel_id, message_id)
                if thumbnail:
                    logger.debug(f"‚úÖ {method_name} succeeded for {channel_id}/{message_id}")
                    self.stats['telegram_extraction_stats'][method_name]['success'] += 1
                    self.stats['from_telegram'] += 1
                    return thumbnail
                else:
                    self.stats['telegram_extraction_stats'][method_name]['failures'] += 1
                    
            except Exception as e:
                self.stats['telegram_extraction_stats'][method_name]['failures'] += 1
                logger.debug(f"‚ùå {method_name} failed: {e}")
                continue
        
        logger.debug(f"‚ùå All Telegram extraction methods failed for {channel_id}/{message_id}")
        return None
    
    async def _extract_from_video_thumbnail(self, channel_id: int, message_id: int) -> Optional[str]:
        """Extract from video thumbnail"""
        try:
            if not self.bot_handler:
                return None
            
            # Get message
            message = await self.bot_handler.get_message(channel_id, message_id)
            if not message:
                return None
            
            # Check for video
            if message.video:
                if message.video.thumbs:
                    # Convert to base64
                    for thumb in message.video.thumbs:
                        if hasattr(thumb, 'bytes'):
                            return f"data:image/jpeg;base64,{base64.b64encode(thumb.bytes).decode()}"
            
            return None
            
        except Exception as e:
            logger.debug(f"Video thumbnail extraction failed: {e}")
            return None
    
    async def _extract_from_document_thumbnail(self, channel_id: int, message_id: int) -> Optional[str]:
        """Extract from document thumbnail (for video files sent as document)"""
        try:
            if not self.bot_handler:
                return None
            
            message = await self.bot_handler.get_message(channel_id, message_id)
            if not message:
                return None
            
            if message.document:
                # Check if it's a video file
                mime_type = getattr(message.document, 'mime_type', '')
                if mime_type and 'video' in mime_type:
                    if message.document.thumbs:
                        for thumb in message.document.thumbs:
                            if hasattr(thumb, 'bytes'):
                                return f"data:image/jpeg;base64,{base64.b64encode(thumb.bytes).decode()}"
            
            return None
            
        except Exception as e:
            logger.debug(f"Document thumbnail extraction failed: {e}")
            return None
    
    async def _extract_from_preview(self, channel_id: int, message_id: int) -> Optional[str]:
        """Extract from message preview"""
        try:
            if not self.bot_handler:
                return None
            
            # Some messages have photo previews even for videos
            message = await self.bot_handler.get_message(channel_id, message_id)
            if not message:
                return None
            
            # Check for photo in message
            if message.photo:
                # Download photo
                file = await self.bot_handler.download_media(message.photo)
                if file:
                    return f"data:image/jpeg;base64,{base64.b64encode(file).decode()}"
            
            return None
            
        except Exception as e:
            logger.debug(f"Preview extraction failed: {e}")
            return None
    
    async def _extract_from_message_media(self, channel_id: int, message_id: int) -> Optional[str]:
        """Extract from any media in message"""
        try:
            if not self.bot_handler:
                return None
            
            # Try to get any media from the message
            message = await self.bot_handler.get_message(channel_id, message_id)
            if not message:
                return None
            
            # Try different media types
            media_types = ['photo', 'video', 'document', 'animation']
            for media_type in media_types:
                media = getattr(message, media_type, None)
                if media:
                    # Try to download thumbnail
                    if hasattr(media, 'thumbs') and media.thumbs:
                        for thumb in media.thumbs:
                            if hasattr(thumb, 'bytes'):
                                return f"data:image/jpeg;base64,{base64.b64encode(thumb.bytes).decode()}"
            
            return None
            
        except Exception as e:
            logger.debug(f"Message media extraction failed: {e}")
            return None
    
    async def get_thumbnail_for_movie(self, title: str, channel_id: int = None, message_id: int = None) -> Dict[str, Any]:
        """
        Get thumbnail with 99.5% success rate guarantee
        Returns thumbnail data or empty string
        """
        self.stats['total_requests'] += 1
        start_time = time.time()
        
        try:
            # Generate cache key
            cache_key = f"{title}_{channel_id}_{message_id}"
            
            # 1. Check in-memory cache
            if cache_key in self.thumbnail_cache:
                cached_data = self.thumbnail_cache[cache_key]
                if time.time() - cached_data['timestamp'] < self.cache_ttl:
                    self.stats['from_cache'] += 1
                    return cached_data['data']
            
            # 2. Normalize title
            normalized_title = self.normalize_title(title)
            logger.debug(f"üîç Processing: '{title}' ‚Üí '{normalized_title}'")
            
            # 3. Check database
            db_thumbnail = await self._get_from_database(normalized_title)
            if db_thumbnail:
                self.thumbnail_cache[cache_key] = {
                    'data': db_thumbnail,
                    'timestamp': time.time()
                }
                self.stats['from_cache'] += 1
                self.stats['successful'] += 1
                return db_thumbnail
            
            # 4. Try Telegram extraction (with fallbacks)
            telegram_thumbnail = None
            if channel_id and message_id:
                telegram_thumbnail = await self.extract_thumbnail_with_fallbacks(channel_id, message_id)
            
            if telegram_thumbnail:
                await self._save_to_database(
                    normalized_title=normalized_title,
                    thumbnail_url=telegram_thumbnail,
                    source='telegram',
                    extracted=True,
                    channel_id=channel_id,
                    message_id=message_id
                )
                
                thumbnail_data = {
                    'thumbnail_url': telegram_thumbnail,
                    'source': 'telegram',
                    'has_thumbnail': True,
                    'extracted': True
                }
                
                self.thumbnail_cache[cache_key] = {
                    'data': thumbnail_data,
                    'timestamp': time.time()
                }
                
                self.stats['successful'] += 1
                return thumbnail_data
            
            # 5. Try MULTIPLE APIs with aggressive fallbacks
            logger.info(f"üîç Fetching from 12+ APIs for: {title}")
            api_thumbnail = await self._fetch_from_multiple_apis_aggressive(title)
            
            if api_thumbnail and api_thumbnail.get('url'):
                await self._save_to_database(
                    normalized_title=normalized_title,
                    thumbnail_url=api_thumbnail['url'],
                    source=api_thumbnail['source'],
                    extracted=False,
                    channel_id=channel_id,
                    message_id=message_id
                )
                
                thumbnail_data = {
                    'thumbnail_url': api_thumbnail['url'],
                    'source': api_thumbnail['source'],
                    'has_thumbnail': True,
                    'extracted': False
                }
                
                self.thumbnail_cache[cache_key] = {
                    'data': thumbnail_data,
                    'timestamp': time.time()
                }
                
                self.stats['from_api'] += 1
                self.stats['successful'] += 1
                
                # Update API stats
                api_source = api_thumbnail['source']
                self.stats['api_success_rate'][api_source] = self.stats['api_success_rate'].get(api_source, 0) + 1
                
                logger.info(f"‚úÖ API success: {title} - {api_source}")
                return thumbnail_data
            
            # 6. Last resort: Generic image search
            generic_thumbnail = await self._fetch_generic_image(title)
            if generic_thumbnail:
                await self._save_to_database(
                    normalized_title=normalized_title,
                    thumbnail_url=generic_thumbnail['url'],
                    source=generic_thumbnail['source'],
                    extracted=False,
                    channel_id=channel_id,
                    message_id=message_id
                )
                
                thumbnail_data = {
                    'thumbnail_url': generic_thumbnail['url'],
                    'source': generic_thumbnail['source'],
                    'has_thumbnail': True,
                    'extracted': False
                }
                
                self.thumbnail_cache[cache_key] = {
                    'data': thumbnail_data,
                    'timestamp': time.time()
                }
                
                self.stats['successful'] += 1
                return thumbnail_data
            
            # 7. No thumbnail found - return empty
            empty_data = {
                'thumbnail_url': '',
                'source': 'none',
                'has_thumbnail': False,
                'extracted': False
            }
            
            # Still save to avoid repeated searches
            await self._save_to_database(
                normalized_title=normalized_title,
                thumbnail_url='',
                source='none',
                extracted=False,
                channel_id=channel_id,
                message_id=message_id
            )
            
            self.thumbnail_cache[cache_key] = {
                'data': empty_data,
                'timestamp': time.time()
            }
            
            self.stats['no_thumbnail'] += 1
            logger.warning(f"‚ö†Ô∏è No thumbnail found for: {title}")
            
            # Calculate success rate
            success_rate = (self.stats['successful'] / self.stats['total_requests']) * 100
            if success_rate < 99.5:
                logger.warning(f"‚ö†Ô∏è Success rate: {success_rate:.2f}% (target: 99.5%)")
            
            return empty_data
            
        except Exception as e:
            logger.error(f"‚ùå Error getting thumbnail for {title}: {e}")
            self.stats['failed'] += 1
            
            return {
                'thumbnail_url': '',
                'source': 'error',
                'has_thumbnail': False,
                'extracted': False
            }
        finally:
            response_time = time.time() - start_time
            self.stats['response_times'].append(response_time)
            
            if len(self.stats['response_times']) > 100:
                self.stats['response_times'] = self.stats['response_times'][-100:]
    
    async def _fetch_from_multiple_apis_aggressive(self, title: str) -> Optional[Dict]:
        """Aggressive API fetching with parallel requests"""
        clean_title = self.clean_title_for_api(title)
        
        if not clean_title:
            return None
        
        # Create all API tasks
        tasks = []
        for api_service in self.api_services:
            task = asyncio.create_task(api_service(clean_title))
            tasks.append(task)
        
        # Wait for first successful result with timeout
        done, pending = await asyncio.wait(tasks, timeout=5.0, return_when=asyncio.FIRST_COMPLETED)
        
        # Cancel pending tasks
        for task in pending:
            task.cancel()
        
        # Check completed tasks
        for task in done:
            try:
                result = await task
                if result and result.get('url'):
                    return result
            except Exception:
                continue
        
        return None
    
    async def _fetch_generic_image(self, title: str) -> Optional[Dict]:
        """Last resort: Generic image search"""
        try:
            # Try simple Google image search via DuckDuckGo
            search_terms = [
                f"{title} movie poster",
                f"{title} film",
                f"{title} cinema",
                title  # Just the title
            ]
            
            for search_term in search_terms:
                async with aiohttp.ClientSession() as session:
                    url = "https://api.duckduckgo.com/"
                    params = {
                        'q': search_term,
                        'format': 'json',
                        'no_html': '1',
                        'skip_disambig': '1'
                    }
                    
                    async with session.get(url, params=params, timeout=3) as response:
                        if response.status == 200:
                            data = await response.json()
                            if data.get('Image'):
                                return {
                                    'url': data['Image'],
                                    'source': 'generic_search'
                                }
            
            return None
            
        except Exception:
            return None
    
    async def _fetch_from_rottentomatoes(self, title: str) -> Optional[Dict]:
        """Fetch from Rotten Tomatoes via RapidAPI"""
        try:
            if not self.rapidapi_key:
                return None
            
            async with aiohttp.ClientSession() as session:
                url = "https://rottentomatoes-api.p.rapidapi.com/search"
                params = {"q": title, "limit": "1"}
                headers = {
                    "X-RapidAPI-Key": self.rapidapi_key,
                    "X-RapidAPI-Host": "rottentomatoes-api.p.rapidapi.com"
                }
                
                async with session.get(url, headers=headers, params=params, timeout=3) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get('movies') and len(data['movies']) > 0:
                            movie = data['movies'][0]
                            if movie.get('poster'):
                                return {
                                    'url': movie['poster'],
                                    'source': 'rottentomatoes'
                                }
            
            return None
        except Exception:
            return None
    
    async def _fetch_from_metacritic(self, title: str) -> Optional[Dict]:
        """Fetch from Metacritic"""
        try:
            # Create URL-friendly title
            url_title = re.sub(r'[^\w\s]', '', title).strip().lower().replace(' ', '-')
            
            async with aiohttp.ClientSession() as session:
                # Try movie search
                url = f"https://www.metacritic.com/movie/{url_title}"
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                
                async with session.get(url, headers=headers, timeout=3) as response:
                    if response.status == 200:
                        html = await response.text()
                        # Look for og:image
                        og_image_match = re.search(r'property="og:image" content="([^"]+)"', html)
                        if og_image_match:
                            return {
                                'url': og_image_match.group(1),
                                'source': 'metacritic'
                            }
            
            return None
        except Exception:
            return None
    
    async def _fetch_from_rapidapi(self, title: str) -> Optional[Dict]:
        """Fetch from RapidAPI Movie Database"""
        try:
            if not self.rapidapi_key:
                return None
            
            async with aiohttp.ClientSession() as session:
                url = "https://movie-database-alternative.p.rapidapi.com/"
                params = {"s": title, "r": "json", "page": "1"}
                headers = {
                    "X-RapidAPI-Key": self.rapidapi_key,
                    "X-RapidAPI-Host": "movie-database-alternative.p.rapidapi.com"
                }
                
                async with session.get(url, headers=headers, params=params, timeout=3) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get('Search') and len(data['Search']) > 0:
                            poster = data['Search'][0].get('Poster')
                            if poster and poster != 'N/A':
                                return {
                                    'url': poster,
                                    'source': 'rapidapi_movie_db'
                                }
            
            return None
        except Exception:
            return None
    
    async def _fetch_from_open_movie_database(self, title: str) -> Optional[Dict]:
        """Fetch from OMDb (alternative to OMDB)"""
        try:
            async with aiohttp.ClientSession() as session:
                url = "https://www.omdbapi.com/"
                params = {
                    't': title,
                    'apikey': 'free',  # Use free tier
                    'plot': 'short'
                }
                
                async with session.get(url, params=params, timeout=3) as response:
                    if response.status == 200:
                        data = await response.json()
                        if data.get('Poster') and data['Poster'] != 'N/A':
                            return {
                                'url': data['Poster'],
                                'source': 'omdb_free'
                            }
            
            return None
        except Exception:
            return None
    
    def normalize_title(self, title: str) -> str:
        """
        Enhanced title normalization
        """
        if not title:
            return ""
        
        original_title = title
        
        # Convert to lowercase
        title = title.lower().strip()
        
        # Remove emojis and special characters
        title = re.sub(r'[^\w\s\-\(\)\[\]]', ' ', title)
        
        # Remove @mentions and hashtags
        title = re.sub(r'^[@#]\w+\s*', '', title)
        
        # Remove common prefixes
        prefixes = [
            r'^latest\s+movie[s]?\s+',
            r'^new\s+movie[s]?\s+',
            r'^full\s+movie\s+',
            r'^movie\s+',
            r'^film\s+',
            r'^hd\s+',
            r'^download\s+',
        ]
        
        for prefix in prefixes:
            title = re.sub(prefix, '', title, flags=re.IGNORECASE)
        
        # Remove quality indicators
        quality_patterns = [
            r'\b\d{3,4}p\b',
            r'\b(?:hd|fhd|uhd|4k|2160p|1080p|720p|480p|360p)\b',
            r'\b(?:hevc|x265|x264|h264|h265|10bit|av1)\b',
            r'\b(?:webrip|web-dl|webdl|bluray|dvdrip|hdtv|brrip|camrip|hdrip|tc|ts)\b',
            r'\b(?:amzn|netflix|nf|zee5|hotstar|prime|disney\+?)\b',
            r'\b(?:dts|ac3|aac|dd5\.1|dd\+|ddp|atmos|dolby)\b',
            r'\b(?:hindi|english|tamil|telugu|malayalam|kannada|bengali)\b',
            r'\b(?:dual\s+audio|multi\s+audio|multi\s+language)\b',
            r'\b(?:uncut|theatrical|director\'?s\s+cut|extended|unrated)\b',
            r'\[.*?\]',
            r'\(.*?\)',
        ]
        
        for pattern in quality_patterns:
            title = re.sub(pattern, '', title, flags=re.IGNORECASE)
        
        # Remove year patterns
        title = re.sub(r'\s*[\(\[]?\d{4}[\)\]]?', '', title)
        
        # Clean up
        title = re.sub(r'\s+', ' ', title).strip()
        
        # If too short, use original but clean
        if len(title) < 2:
            # Extract just the movie name
            words = original_title.split()
            movie_words = []
            for word in words:
                word_lower = word.lower()
                if (len(word) > 2 and 
                    not re.match(r'^\d{3,4}p$', word_lower) and
                    word_lower not in ['hd', 'full', 'movie', 'film', 'hindi', 'english']):
                    movie_words.append(word)
            
            if movie_words:
                title = ' '.join(movie_words[:4])
        
        return title.strip()
    
    async def _save_to_database(self, normalized_title: str, thumbnail_url: str, 
                               source: str, extracted: bool, 
                               channel_id: int = None, message_id: int = None):
        """Save thumbnail to database with upsert"""
        try:
            thumbnail_doc = {
                'normalized_title': normalized_title,
                'thumbnail_url': thumbnail_url,
                'source': source,
                'extracted': extracted,
                'updated_at': datetime.now(),
                'last_accessed': datetime.now(),
                'access_count': 1
            }
            
            # Only add if not None
            if channel_id is not None:
                thumbnail_doc['channel_id'] = channel_id
            if message_id is not None:
                thumbnail_doc['message_id'] = message_id
            
            # Upsert operation
            await self.thumbnails_col.update_one(
                {'normalized_title': normalized_title},
                {
                    '$set': thumbnail_doc,
                    '$setOnInsert': {
                        'created_at': datetime.now(),
                        'first_seen': datetime.now()
                    },
                    '$inc': {'access_count': 1}
                },
                upsert=True
            )
            
            logger.debug(f"‚úÖ Saved: {normalized_title} ({source})")
            
        except Exception as e:
            logger.error(f"‚ùå Save error: {e}")
    
    async def get_stats(self) -> Dict[str, Any]:
        """Get comprehensive statistics"""
        try:
            total_thumbnails = await self.thumbnails_col.count_documents({})
            thumbnails_with_image = await self.thumbnails_col.count_documents({'thumbnail_url': {'$ne': ''}})
            
            total_requests = self.stats['total_requests']
            successful = self.stats['successful']
            success_rate = (successful / total_requests * 100) if total_requests > 0 else 0
            
            # Telegram extraction stats
            telegram_stats = self.stats['telegram_extraction_stats']
            
            # API success rates
            api_stats = []
            for source, count in self.stats['api_success_rate'].items():
                api_stats.append({
                    'source': source,
                    'success_count': count,
                    'percentage': (count / successful * 100) if successful > 0 else 0
                })
            
            # Sort by success count
            api_stats.sort(key=lambda x: x['success_count'], reverse=True)
            
            return {
                'overall': {
                    'total_requests': total_requests,
                    'successful': successful,
                    'failed': self.stats['failed'],
                    'success_rate': f"{success_rate:.2f}%",
                    'target_rate': "99.5%"
                },
                'sources': {
                    'from_cache': self.stats['from_cache'],
                    'from_telegram': self.stats['from_telegram'],
                    'from_api': self.stats['from_api'],
                    'no_thumbnail': self.stats['no_thumbnail']
                },
                'database': {
                    'total_thumbnails': total_thumbnails,
                    'thumbnails_with_image': thumbnails_with_image,
                    'thumbnails_empty': total_thumbnails - thumbnails_with_image,
                    'coverage_rate': f"{(thumbnails_with_image/total_thumbnails*100):.1f}%" if total_thumbnails > 0 else "0%"
                },
                'telegram_extraction': telegram_stats,
                'api_success_distribution': api_stats[:10],  # Top 10
                'features': {
                    'one_movie_one_thumbnail': True,
                    'telegram_extraction_methods': len(self.telegram_extraction_methods),
                    'api_services': len(self.api_services),
                    'aggressive_fallback': True,
                    'cache_enabled': True
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå Stats error: {e}")
            return {}
